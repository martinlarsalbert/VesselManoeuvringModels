{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "0a4fd30d-2989-42e5-a09a-7e4283ce66ea",
            "metadata": {},
            "source": [
                "# Linear Regression Covariance\n",
                "When conduction linear regression the coefficients in the model become random variables. The [slope](https://online.stat.psu.edu/stat200/lesson/7/7.4) in a linear regression is a Gausian random variable, which means that the coefficients are also Gausian. The regressed coefficients from a linear regression represent the mean values of these random variables, being the most likely values. But the random coefficients also have standard deviations which means that there are also other possible values for the coefficients, less likely, but still possible. And in some cases when the coefficients are very uncertain (high standard deviation) the other possible values are almost as likely, which means that we should also consider these as possible values for the coefficients. \n",
                "\n",
                "In this example we will fit a linear regression model using Ordinary Least Squares (OLS) on a generic dataset where the coefficients in the model are very uncertain due to multicollinearity which means that there is a high correlation between the variables (features) in the model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "855d1c0e-a9fb-4b4e-9fa1-1d5c97f72f26",
            "metadata": {
                "tags": [
                    "remove-cell"
                ]
            },
            "outputs": [],
            "source": [
                "# %load imports.py\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "%config Completer.use_jedi = False  ## (To fix autocomplete)\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import os.path\n",
                "\n",
                "import matplotlib\n",
                "matplotlib.rcParams[\"figure.figsize\"] = (15,4)\n",
                "from vessel_manoeuvring_models.symbols import *\n",
                "import statsmodels.api as sm\n",
                "from scipy.stats import norm\n",
                "from scipy.stats import norm, multivariate_normal"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c464003c-5198-4afe-ba5c-9f4c5923c5df",
            "metadata": {},
            "source": [
                "This is the model that we think will fit the generic dataset:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cdd6ca31-13d1-4fff-8e41-74403351e0f3",
            "metadata": {
                "tags": [
                    "hide-input",
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "C_1,C_2, x_1, x_2, y = sp.symbols(\"C_1 C_2 x_1 x_2 y\")\n",
                "epsilon_1, epsilon_2, z = sp.symbols(\"epsilon_1 epsilon_2 z\")\n",
                "eq_linear = sp.Eq(y, C_1*x_1 + C_2*x_2)\n",
                "eq_linear"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d30d65c9-ac67-4ae4-b171-559a6872adf3",
            "metadata": {},
            "source": [
                "$C_1$ is a coefficient connected to the variable (feature) $x_1$ and $C_2$ is the same thing for $x_2$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aec9fc8a-9a44-4909-a704-bcbac91ca87a",
            "metadata": {
                "tags": [
                    "remove-cell"
                ]
            },
            "outputs": [],
            "source": [
                "solution = sp.solve(eq_linear, y, dict=True)[0][y]\n",
                "lambda_y = sp.lambdify(list(solution.free_symbols), solution)\n",
                "lambda_y"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3a7e22a2-b6f0-4b10-b7bb-a714267ad5c5",
            "metadata": {},
            "source": [
                "We create the generic dataset where $x_1$ and $x_2$ both have some Gausian noise, $y$ is however calculated directly from the above equation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2bb771bb-c686-4354-acf9-376effb36576",
            "metadata": {
                "tags": [
                    "hide-input"
                ]
            },
            "outputs": [],
            "source": [
                "scale = 0.5\n",
                "epsilon_1_ = norm(loc=0, scale=scale)\n",
                "epsilon_2_ = norm(loc=0, scale=scale)\n",
                "\n",
                "C_1_ = 1 \n",
                "C_2_ = 5 \n",
                "\n",
                "N = 200\n",
                "data = pd.DataFrame()\n",
                "data['epsilon_1'] = epsilon_1_.rvs(N)\n",
                "data['epsilon_2'] = epsilon_2_.rvs(N)\n",
                "\n",
                "data['x_1'] = np.linspace(0,5,N) \n",
                "data['x_2'] = np.linspace(0,5,N)\n",
                "data['x_1_measure'] = data['x_1'] + data['epsilon_1']\n",
                "data['x_2_measure'] = data['x_2'] + data['epsilon_2']\n",
                "\n",
                "np.random.seed(42)\n",
                "data['y'] = lambda_y(C_1=C_1_, C_2=C_2_, x_1=data['x_1'], x_2=data['x_2'])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1fa52e93-78fa-4601-b30d-b2b5b73bd689",
            "metadata": {},
            "source": [
                "Plotting $x_1$ against $x_2$ show that there is a high correlation between these variables:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9776854f-f500-42dd-9c09-2e238dc10096",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "fig,ax=plt.subplots()\n",
                "data.plot(x='x_1_measure', y='x_2_measure', style='.', label='measurements', ax=ax);\n",
                "data.plot(x='x_1', y='x_2', style='-', label='real', ax=ax);\n",
                "ax.set_xlabel('$x_1$')\n",
                "ax.set_ylabel('$x_2$');"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3fbbf744-337a-4485-8687-e3290517f9d6",
            "metadata": {},
            "source": [
                "And here are $y$ values calculated from the noise measurements of $x_1$ and $x_2$:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7c0ae92-a85a-40f7-a33d-497c1922c173",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "fig,ax=plt.subplots()\n",
                "data.plot(x='x_1_measure', y='y', style='o', label='$x_1$ (measure)', ax=ax);\n",
                "data.plot(x='x_2_measure', y='y', style='.', label='$x_2$ (measure)', ax=ax);\n",
                "\n",
                "ax.set_xlabel('$x_1$, $x_2$')\n",
                "ax.set_ylabel('$y$');"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "84a718c5-8607-42fe-a92d-77b223b1a2d2",
            "metadata": {},
            "source": [
                "Regressing $C_1$ and $C_2$ on this generic dataset gives the following:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "80776f79-d6c4-4abb-b6c5-cf857bbda0d2",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "X = pd.DataFrame(index=data.index)\n",
                "X['C_1'] = data['x_1_measure']\n",
                "X['C_2'] = data['x_2_measure']\n",
                "\n",
                "model = sm.OLS(data['y'], X, hasconst=True)\n",
                "result = model.fit()\n",
                "\n",
                "result.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b7a82697-ab4c-47ce-b48e-7d8aea5b5758",
            "metadata": {},
            "source": [
                "We used $C_1=1$ , $C_2=5$ when we created the generic data but the regression has predicted $C_1=2.6\t$ , $C_2=2.3$ but we can also see that the standard deviation ```std err``` is high, so the predicted coefficients are very uncertain. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a360df6f-bea0-411b-aea1-5e00ca441a73",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "x_ = np.linspace(data['x_1_measure'].min(),data['x_1_measure'].max(),2)\n",
                "\n",
                "\n",
                "fig,ax=plt.subplots()\n",
                "data.plot(x='x_1_measure', y='y', style='o', label='$x_1$ (measure)', ax=ax);\n",
                "data.plot(x='x_2_measure', y='y', style='.', label='$x_2$ (measure)', ax=ax);\n",
                "\n",
                "y_pred = lambda_y(x_1=x_, x_2=x_, **result.params)\n",
                "ax.plot(x_,y_pred,'k-', alpha=1, lw=2, zorder=10, label='OLS regression $(x_1=x_2)$')\n",
                "    \n",
                "ax.set_ylim(-10,40)\n",
                "ax.set_xlabel('$x_1$,$x_2$')\n",
                "ax.set_ylabel('$y$')\n",
                "ax.legend();"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4c9904be-61ac-4dca-ba73-a760e1461872",
            "metadata": {},
            "source": [
                "The random variables $C_1$ and $C_2$ are Gausian and come from a Normal distribution with mean value and standrad deviation. With two or more random variables a multivariate normal distribution is used. The contour plot from this multivariate normal distribution with mean values and standard deviation from the regression is shown below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8168ba3a-fecb-4e05-87cd-7bc6e750789d",
            "metadata": {
                "tags": [
                    "hide-input"
                ]
            },
            "outputs": [],
            "source": [
                "cov2 = np.diag(np.sqrt(result.bse))\n",
                "rv2 = multivariate_normal(mean=result.params, cov=cov2)\n",
                "\n",
                "N_ = 50\n",
                "dx_ = 3*np.sqrt(cov2.max().max())\n",
                "x_1_ = np.linspace(result.params['C_1'] - dx_ , result.params['C_1'] + dx_,N_)\n",
                "x_2_ = np.linspace(result.params['C_2'] - dx_ , result.params['C_2'] + dx_,N_)\n",
                "\n",
                "\n",
                "X1,X2 = np.meshgrid(x_1_, x_2_)\n",
                "xs = np.array([X1.flatten(),X2.flatten()])\n",
                "ls = rv2.pdf(xs.T)\n",
                "L = ls.reshape(X1.shape)\n",
                "\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "#fig = plt.figure()\n",
                "#ax = fig.add_subplot(111, projection='3d')\n",
                "fig,ax=plt.subplots()\n",
                "ax.contourf(X1,X2,L,levels=10)\n",
                "ax.set_xlabel('$C_1$')\n",
                "ax.set_ylabel('$C_2$');"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc2b7222-4661-4954-90f7-40180259d73f",
            "metadata": {},
            "source": [
                "For this case $C_1$ and $C_2$ are treated as independet random variables, which means that if $C_1$ has a high value, this will not influence the likelihood that $C_2$ can also have a high value. This is however not true in our problem. If $C_1$ is very large: 1000, $C_2$ can not also be very large, then the initial model will not add upp.\n",
                "\n",
                "The regression also predicts the covariance of the random variables, also containing the dependency between $C_1$ and $C_2$. The contour plot of the distribution now looks like:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f764a22-a63e-4cea-be2e-32e11516fc9e",
            "metadata": {
                "tags": [
                    "hide-input"
                ]
            },
            "outputs": [],
            "source": [
                "cov = result.cov_HC0\n",
                "rv = multivariate_normal(mean=result.params, cov=cov)\n",
                "\n",
                "N_ = 50\n",
                "dx_ = 3*np.sqrt(cov.max().max())\n",
                "x_1_ = np.linspace(result.params['C_1'] - dx_ , result.params['C_1'] + dx_,N_)\n",
                "x_2_ = np.linspace(result.params['C_2'] - dx_ , result.params['C_2'] + dx_,N_)\n",
                "\n",
                "\n",
                "X1,X2 = np.meshgrid(x_1_, x_2_)\n",
                "xs = np.array([X1.flatten(),X2.flatten()])\n",
                "ls = rv.pdf(xs.T)\n",
                "L = ls.reshape(X1.shape)\n",
                "\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "#fig = plt.figure()\n",
                "#ax = fig.add_subplot(111, projection='3d')\n",
                "fig,ax=plt.subplots()\n",
                "ax.contourf(X1,X2,L,levels=10)\n",
                "ax.set_xlabel('$C_1$')\n",
                "ax.set_ylabel('$C_2$');\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4599dc91-8e97-46e1-80e4-4e1f732bde66",
            "metadata": {},
            "source": [
                "It can now be seen that if $C_1$ is large then it is more likely that $C_2$ will be small."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c2a19d4-b8d1-4986-9274-be2415e17dba",
            "metadata": {},
            "source": [
                "We can take random samples from these multivariate distributions to simulate alternative realizations of this model. Sampling from a distribution with independent variables (only mean and standard deviation) and a distribution with dependent variables (mean and covariance) is shown below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "67cdc956-8235-4de3-a91b-7dd33b4081b7",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "N_=50\n",
                "df_Cs_rv = pd.DataFrame(rv.rvs(N_), columns=['C_1','C_2'])\n",
                "df_Cs_rv2 = pd.DataFrame(rv2.rvs(N_), columns=['C_1','C_2'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59f34f33-1a30-4e4c-924c-fac0013e28ac",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "titles = ['Independent (mean, std)', 'Dependent (mean, std, cov)']\n",
                "\n",
                "x_ = np.linspace(data['x_1_measure'].min(),data['x_1_measure'].max(),2)\n",
                "for df_Cs,title in zip([df_Cs_rv2,df_Cs_rv],titles):\n",
                "\n",
                "    fig,ax=plt.subplots()\n",
                "    data.plot(x='x_1_measure', y='y', style='o', label='$x_1$ (measure)', ax=ax);\n",
                "    data.plot(x='x_2_measure', y='y', style='.', label='$x_2$ (measure)', ax=ax);\n",
                "    \n",
                "    data.plot(x='x_1',y='y', style='b-', ax=ax, alpha=1, lw=2, zorder=12, label='Real model $(x_1=x_2)$')\n",
                "    \n",
                "    y_pred = lambda_y(x_1=x_, x_2=x_, **result.params)\n",
                "    ax.plot(x_,y_pred,'k-', alpha=1, lw=2, zorder=10, label='OLS regression $(x_1=x_2)$')\n",
                "    \n",
                "    for index, Cs in df_Cs.iterrows():\n",
                "        \n",
                "        y_pred = lambda_y(x_1=x_, x_2=x_, **Cs)\n",
                "        ax.plot(x_,y_pred,'r-', alpha=0.1, lw=2)\n",
                "        \n",
                "    ax.set_ylim(-10,40)\n",
                "    ax.set_xlabel('$x_1$,$x_2$')\n",
                "    ax.set_ylabel('$y$')\n",
                "    ax.set_title(title)\n",
                "    ax.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "826dd160-3893-4ff7-8a04-0c5644447687",
            "metadata": {},
            "source": [
                "The alternative models from the multivariate distribution with dependent variables have less spread. The \"Real model\" that was used to generate the generic data is however very different. Only when sampling from the distribution with independent variables, some of the solutions are close to the real model.\n",
                "\n",
                "In this example it was impossible to identify which model that was the \"Real model\", because there were so many alternative models that could have created the same data. In fact the generic data is more likely originating from the regressed model, than the one we actually used. To better handle the multicollinearity it is most likely better to redefine the regression model as:\n",
                "\n",
                "$y=C_1*(x_1+x_2)$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b6edd5ae-6cad-4c61-bb8f-d51db82d84a2",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "X2 = pd.DataFrame(index=data.index)\n",
                "X2['C_1'] = data['x_1_measure'] + data['x_2_measure']\n",
                "\n",
                "model = sm.OLS(data['y'], X2, hasconst=True)\n",
                "result = model.fit()\n",
                "\n",
                "result.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad5793e2-943d-475d-b778-de2169ea044b",
            "metadata": {
                "tags": [
                    "remove-input"
                ]
            },
            "outputs": [],
            "source": [
                "cov = result.cov_HC0\n",
                "rv3 = multivariate_normal(mean=result.params, cov=cov)\n",
                "df_Cs_rv3 = pd.DataFrame(rv3.rvs(N_), columns=['C_1'])\n",
                "\n",
                "\n",
                "fig,ax=plt.subplots()\n",
                "data.plot(x='x_1_measure', y='y', style='o', label='$x_1$ (measure)', ax=ax);\n",
                "data.plot(x='x_2_measure', y='y', style='.', label='$x_2$ (measure)', ax=ax);\n",
                "\n",
                "data.plot(x='x_1',y='y', style='b-', ax=ax, alpha=1, lw=2, zorder=12, label='Real model $(x_1=x_2)$')\n",
                "\n",
                "y_pred = result.params['C_1']*(2*x_)\n",
                "ax.plot(x_,y_pred,'k-', alpha=1, lw=2, zorder=10, label='OLS regression $(x_1=x_2)$')\n",
                "\n",
                "for index, Cs in df_Cs_rv3.iterrows():\n",
                "    \n",
                "    y_pred = Cs['C_1']*(2*x_)\n",
                "    ax.plot(x_,y_pred,'r-', alpha=0.1, lw=2)\n",
                "    \n",
                "ax.set_ylim(-10,40)\n",
                "ax.set_xlabel('$x_1$,$x_2$')\n",
                "ax.set_ylabel('$y$')\n",
                "ax.set_title(title)\n",
                "ax.legend();\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3b39d29-269b-40f1-8ab9-ac0ce6fe1fe2",
            "metadata": {},
            "source": [
                "### Final words\n",
                "This model has the same prediction accuracy, but only one coefficient with higher certainty. \n",
                "So when regressing a model \"less is more\" is perhaps a good rule in terms of adding coefficients and complexity to the model and this is true for Vessel Manoeuvring Models as well. \n",
                "\n",
                "For heavy metal the reversed is however still true, perhaps best quoted by Mr Yngwie Malmsteen :-).\n",
                "<iframe width=\"560\" height=\"315\" vessel_manoeuvring_models=\"https://www.youtube.com/embed/QHZ48AE3TOI\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}